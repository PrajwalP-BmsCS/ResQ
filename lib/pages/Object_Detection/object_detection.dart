import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:flutter/services.dart';
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';
import 'package:req_demo/pages/Flutter_STT/language_translation.dart';
import 'package:req_demo/pages/Flutter_TTS/tts.dart';
import 'package:req_demo/pages/utils/util.dart';

class ObjectDetectionScreen extends StatefulWidget {
  final String language;
  ObjectDetectionScreen({required this.language});

  @override
  _ObjectDetectionScreenState createState() => _ObjectDetectionScreenState();
}

class _ObjectDetectionScreenState extends State<ObjectDetectionScreen> {
  File? _capturedImage;
  List<dynamic>? _detections;
  static const platform = MethodChannel('onnx_channel');
  bool _isDetecting = false;
  String appTitle = "";
  String imageNote = "";
  String finalResult = "";

  // ‚ö° your ESP32 CAM endpoint
  final String esp32Url = '$espBaseUrl/capture';

  @override
  void initState() {
    super.initState();

    _fetchAndDetect();
  }

  Future<void> _fetchAndDetect() async {
    if (widget.language != "English") {
      print("LANG ${widget.language}");
      setState(() {
        // _isDetecting = true;
        appTitle = "‡≤µ‡≤∏‡≥ç‡≤§‡≥Å ‡≤™‡≤§‡≥ç‡≤§‡≥Ü";
        imageNote = "‡≤á‡≤®‡≥ç‡≤®‡≥Ç ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ü‡≤∞‡≥Ü‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≤≤‡≤æ‡≤ó‡≤ø‡≤≤‡≥ç‡≤≤";
      });
    } else {
      setState(() {
        _isDetecting = true;
        appTitle = "Object Detection";
      });
    }

    try {
      // add timestamp param to force ESP32 refresh
      final String url =
          '$esp32Url?cb=${DateTime.now().millisecondsSinceEpoch}';
      final response = await http.get(Uri.parse(url));
      print("üì∏ Fetching from $url");

      if (response.statusCode != 200) {
        throw Exception('Failed to load image from ESP32');
      }

      // save image with unique filename
      final Directory tempDir = await getTemporaryDirectory();
      final String filePath =
          '${tempDir.path}/capture_${DateTime.now().millisecondsSinceEpoch}.jpg';
      final File imageFile = File(filePath);
      await imageFile.writeAsBytes(response.bodyBytes);

      setState(() {
        _capturedImage = imageFile;
      });

      // üöÄ Run YOLO ONNX inference
      final List<dynamic> result =
          await platform.invokeMethod('runYOLO', {'path': imageFile.path});

      setState(() {
        _detections = result;
        _isDetecting = false;
      });

      // üó£Ô∏è Speak results
      if (result.isNotEmpty) {
        String detectedObjects = result.join(", ");
        detectedObjects += "I am seeing" + detectedObjects + "in front me";

        if (widget.language != "English") {
          detectedObjects = (await TranslationService.translateWithMyMemory(
              detectedObjects, "en|kn"))!;
        }
        await TTSManager().speak("$detectedObjects");

        setState(() {
          finalResult = detectedObjects;
        });
      } else {
        await TTSManager().speak(widget.language == "English"
            ? "No objects detected"
            : "‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤µ‡≤∏‡≥ç‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤™‡≤§‡≥ç‡≤§‡≥Ü‡≤Ø‡≤æ‡≤ó‡≤ø‡≤≤‡≥ç‡≤≤");
      }
    } catch (e) {
      print("‚ùå Error fetching/detecting: $e");
      setState(() => _isDetecting = false);
      await TTSManager().speak(widget.language == "English"
          ? "No objects detected"
          : "‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤µ‡≤∏‡≥ç‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤™‡≤§‡≥ç‡≤§‡≥Ü‡≤Ø‡≤æ‡≤ó‡≤ø‡≤≤‡≥ç‡≤≤");
    }
  }

  @override
  void dispose() {
    TTSManager().stop();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text(appTitle)),
      body: Center(
        child: Padding(
          padding: const EdgeInsets.all(20),
          child: _isDetecting
              ? Column(
                  mainAxisAlignment: MainAxisAlignment.center,
                  children: [
                    CircularProgressIndicator(),
                    SizedBox(height: 20),
                    Text(
                      widget.language == "English"
                          ? "Capturing and detecting..."
                          : "‡≤∏‡≥Ü‡≤∞‡≥Ü‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≤§‡≥ç‡≤§‡≥Ü‡≤π‡≤ö‡≥ç‡≤ö‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å...",
                    ),
                  ],
                )
              : _capturedImage == null
                  ? Text(imageNote)
                  : Column(
                      children: [
                        FutureBuilder<Uint8List>(
                          future: _capturedImage?.readAsBytes(),
                          builder: (context, snapshot) {
                            if (!snapshot.hasData)
                              return CircularProgressIndicator();
                            return Image.memory(
                              snapshot.data!,
                              height: 250,
                              gaplessPlayback: true, // prevents old frame flash
                            );
                          },
                        ),
                        const SizedBox(height: 20),
                        if (finalResult != null)
                          Text(
                            widget.language == "English"
                                ? "Detected Objects: ${finalResult}"
                                : "‡≤™‡≤§‡≥ç‡≤§‡≥Ü‡≤Ø‡≤æ‡≤¶ ‡≤µ‡≤∏‡≥ç‡≤§‡≥Å‡≤ó‡≤≥‡≥Å: ${finalResult}",
                            style: TextStyle(fontSize: 16),
                          ),
                        const SizedBox(height: 20),
                        ElevatedButton.icon(
                          onPressed: _fetchAndDetect,
                          icon: Icon(Icons.refresh),
                          label: Text("Capture Again"),
                        ),
                      ],
                    ),
        ),
      ),
    );
  }
}
